{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THE CODE FOR THIS ALGORITHM WAS TAKEN FROM HERE: https://github.com/cltl/ba-text-mining/blob/master/lab_sessions/lab4/Lab4a.4-NERC-CRF-Dutch.ipynb\n",
    "### AS WELL AS THE SKLEARN DOCUMENTATION, AND SUBSEQUENTLY ADJUSTED FOR OUR SPECIFIC DATA!\n",
    "\n",
    "# Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: YOU NEED TO HAVE SKLEARN-VERSION < 0.24 IN ORDER TO RUN PART OF THE CODE\n",
    "### LATER VERSIONS WILL NOT WORK, SEE: https://github.com/TeamHG-Memex/sklearn-crfsuite/issues/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sents_from_tsv(inputfile):\n",
    "    sents = []\n",
    "    current_sent = []\n",
    "\n",
    "    with open(inputfile, \"r\") as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        next(reader)\n",
    "        for line in infile:\n",
    "            # using tsv files here as the csv files get split incorrectly \n",
    "            row = line.strip(\"\\n\").split('\\t')\n",
    "            if row[4] == \".\":\n",
    "                current_sent.append(tuple(row))\n",
    "                sents.append(current_sent)\n",
    "                current_sent = []\n",
    "            else:\n",
    "                current_sent.append(tuple(row))\n",
    "    return sents\n",
    "\n",
    "def token2features(sentence, i):\n",
    "    story = sentence[i][1]\n",
    "    sent_index = sentence[i][2]\n",
    "    token_index = sentence[i][3]\n",
    "    prev_prev_token= sentence[i][4]\n",
    "    prev_token = sentence[i][5]\n",
    "    token = sentence[i][6]\n",
    "    next_token = sentence[i][7]\n",
    "    next_next_token = sentence[i][8]\n",
    "    pos = sentence[i][9]\n",
    "    chunk = sentence[i][10]\n",
    "    lemma= sentence[i][11]\n",
    "    matchesNeg = sentence[i][12]\n",
    "    hasPrefix = sentence[i][13]\n",
    "    hasSuffix = sentence[i][14]\n",
    "    hasPrefixAntonym = sentence[i][15]\n",
    "    hasSuffixAntonym = sentence[i][16]\n",
    "    matchesMulticue = sentence[i][17]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'story':story,\n",
    "        'sent_index':sent_index,\n",
    "        'token_index':token_index,\n",
    "        'token-2':prev_prev_token,\n",
    "        'token-1':prev_token,\n",
    "        'token': token,\n",
    "        'token+1':next_token,\n",
    "        'token+2': next_next_token,\n",
    "        'pos': pos,\n",
    "        'chunk':chunk,\n",
    "        'lemma':lemma,\n",
    "        'matchesNeg':matchesNeg,\n",
    "        'hasPrefix':hasPrefix,\n",
    "        'hasSuffix':hasSuffix,\n",
    "        'hasPrefixAntonym':hasPrefixAntonym,\n",
    "        'hasSuffixAntonym':hasSuffixAntonym,\n",
    "        'matchesMulticue':matchesMulticue\n",
    "    }\n",
    "        \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [token2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    # gold labels at index 18\n",
    "    return [word[18] for word in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    # tokens at index 6\n",
    "    return [word[6] for word in sent]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature files obtained by running pipeline main_B.py and converting df to a tsv\n",
    "train_sents = extract_sents_from_tsv(\"training_features_B.tsv\")\n",
    "test_sents = extract_sents_from_tsv(\"dev_features_B.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]\n",
    "Y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "Y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellem\\anaconda3\\lib\\site-packages\\sklearn\\base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=CRF(algorithm='lbfgs',\n",
       "                                 all_possible_transitions=True,\n",
       "                                 keep_tempfiles=None, max_iterations=100),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002C3C2AE0B50>,\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002C3B1285460>},\n",
       "                   scoring=make_scorer(flat_f1_score, average=weighted),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Taken from the sklearn documentation: https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#features\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', max_iterations=100, all_possible_transitions=True)\n",
    "params_space = {'c1': scipy.stats.expon(scale=0.5), 'c2': scipy.stats.expon(scale=0.05)}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score, average='weighted')\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space, cv=3, verbose=1, n_jobs=-1, n_iter=50, scoring=f1_scorer)\n",
    "rs.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for CRF: {'c1': 0.10816419273720317, 'c2': 0.0052509679623781455}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters for CRF:\", rs.best_params_)\n",
    "crf = rs.best_estimator_\n",
    "labels = list(crf.classes_)\n",
    "Y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_labels = sorted(labels, key=lambda name: (name[1:], name[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O     0.9982    0.9990    0.9986     13375\n",
      "       B-NEG     0.9217    0.8693    0.8947       176\n",
      "       I-NEG     1.0000    0.6667    0.8000         3\n",
      "\n",
      "    accuracy                         0.9973     13554\n",
      "   macro avg     0.9733    0.8450    0.8978     13554\n",
      "weighted avg     0.9972    0.9973    0.9972     13554\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellem\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass labels=['O', 'B-NEG', 'I-NEG'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(Y_test, Y_pred, labels=sorted_labels, digits=4))\n",
    "# report = pd.DataFrame(classification_report(y_true=Y_test, y_pred=Y_pred, output_dict=True)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe to check which labels don't overlap\n",
    "\n",
    "trial_df = pd.DataFrame()\n",
    "pred_labels = []\n",
    "for small_list in Y_pred:\n",
    "    for label in small_list:\n",
    "        pred_labels.append(label)\n",
    "        \n",
    "trial_df['predicted_label'] = pred_labels\n",
    "\n",
    "gold_labels = []\n",
    "for small_list in Y_test:\n",
    "    for label in small_list:\n",
    "        gold_labels.append(label)\n",
    "        \n",
    "trial_df['gold_label'] = gold_labels\n",
    "\n",
    "test_tokens = []\n",
    "for small_list in test_sents:\n",
    "    for token_tuple in small_list:\n",
    "        test_tokens.append(token_tuple[6])\n",
    "trial_df['token'] = test_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>unbrushed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>unshaven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>unbrushed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>unkempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>unburned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>undoubtedly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3625</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>uncommonly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>unnatural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>irreproachable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5035</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>insensibly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5184</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>inadmissable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5242</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>insufferable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7412</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>needless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>Save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7648</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8832</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9338</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>sapless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>undoubtedly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10250</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10406</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11222</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>fearless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13094</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13505</th>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>unclean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      predicted_label gold_label           token\n",
       "800                 O      B-NEG       unbrushed\n",
       "805                 O      B-NEG        unshaven\n",
       "946                 O      B-NEG       unbrushed\n",
       "948                 O      B-NEG         unkempt\n",
       "3056                O      B-NEG        unburned\n",
       "3297                O      B-NEG     undoubtedly\n",
       "3625                O      B-NEG      uncommonly\n",
       "4586                O      B-NEG       unnatural\n",
       "4949                O      B-NEG  irreproachable\n",
       "5035                O      B-NEG      insensibly\n",
       "5184                O      B-NEG    inadmissable\n",
       "5242                O      B-NEG    insufferable\n",
       "7412                O      B-NEG        needless\n",
       "7474                O      B-NEG            Save\n",
       "7648                O      B-NEG    dissatisfied\n",
       "8832                O      B-NEG         unknown\n",
       "9338                O      B-NEG         sapless\n",
       "9354                O      B-NEG     undoubtedly\n",
       "10250               O      B-NEG         nothing\n",
       "10406               O      B-NEG         unknown\n",
       "11222               O      B-NEG        fearless\n",
       "13094               O      B-NEG             not\n",
       "13505               O      B-NEG         unclean"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_df[(trial_df['gold_label'] == \"B-NEG\") & (trial_df['predicted_label'] != \"B-NEG\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13008</th>\n",
       "      <td>O</td>\n",
       "      <td>I-NEG</td>\n",
       "      <td>more</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      predicted_label gold_label token\n",
       "13008               O      I-NEG  more"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_df[(trial_df['gold_label'] == \"I-NEG\") & (trial_df['predicted_label'] != \"I-NEG\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
