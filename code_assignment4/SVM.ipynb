{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0       story  sent_index  token_index   token-2     token-1  \\\n",
      "0               0  wisteria01           0            0         X           X   \n",
      "1               1  wisteria01           0            1         X          1.   \n",
      "2               2  wisteria01           0            2        1.         The   \n",
      "3               3  wisteria01           0            3       The    Singular   \n",
      "4               4  wisteria01           0            4  Singular  Experience   \n",
      "...           ...         ...         ...          ...       ...         ...   \n",
      "13562       13562  wisteria02         439            9       was        very   \n",
      "13563       13563  wisteria02         439           10      very    orthodox   \n",
      "13564       13564  wisteria02         439           11  orthodox          in   \n",
      "13565       13565  wisteria02         439           12        in         his   \n",
      "13566       13566  wisteria02         439           13       his      ritual   \n",
      "\n",
      "            token     token+1     token+2   pos     chunk       lemma  \\\n",
      "0              1.         The    Singular    CD  no label          1.   \n",
      "1             The    Singular  Experience    DT        NP         The   \n",
      "2        Singular  Experience          of    JJ        NP    Singular   \n",
      "3      Experience          of         Mr.    NN        NP  Experience   \n",
      "4              of         Mr.        John    IN        PP          of   \n",
      "...           ...         ...         ...   ...       ...         ...   \n",
      "13562    orthodox          in         his    JJ      ADJP    orthodox   \n",
      "13563          in         his      ritual    IN        PP          in   \n",
      "13564         his      ritual           .  PRP$        PP         his   \n",
      "13565      ritual           .           X    NN        PP      ritual   \n",
      "13566           .           X           X     .  no label           .   \n",
      "\n",
      "       matchesNeg  hasPrefix  hasSuffix  hasPrefixAntonym  hasSuffixAntonym  \\\n",
      "0           False      False      False             False             False   \n",
      "1           False      False      False             False             False   \n",
      "2           False      False      False             False             False   \n",
      "3           False      False      False             False             False   \n",
      "4           False      False      False             False             False   \n",
      "...           ...        ...        ...               ...               ...   \n",
      "13562       False      False      False             False             False   \n",
      "13563       False      False      False             False             False   \n",
      "13564       False      False      False             False             False   \n",
      "13565       False      False      False             False             False   \n",
      "13566       False      False      False             False             False   \n",
      "\n",
      "       matchesMulticue bio  \n",
      "0                False   O  \n",
      "1                False   O  \n",
      "2                False   O  \n",
      "3                False   O  \n",
      "4                False   O  \n",
      "...                ...  ..  \n",
      "13562            False   O  \n",
      "13563            False   O  \n",
      "13564            False   O  \n",
      "13565            False   O  \n",
      "13566            False   O  \n",
      "\n",
      "[13567 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/training_features_B.tsv', sep=\"\\t\")\n",
    "dev_df = pd.read_csv('./data/dev_features_B.tsv', sep=\"\\t\")\n",
    "print(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns other than token feature and targets\n",
    "train_df = train_df.drop(columns=[\"story\", \"sent_index\", \"token_index\"], axis=1)\n",
    "dev_df = dev_df.drop(columns=[\"story\", \"sent_index\", \"token_index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  token-2   token-1     token   token+1   token+2  pos  \\\n",
      "0               0        X         X   Chapter        1.       Mr.   NN   \n",
      "1               1        X   Chapter        1.       Mr.  Sherlock   CD   \n",
      "2               2  Chapter        1.       Mr.  Sherlock    Holmes  NNP   \n",
      "3               3       1.       Mr.  Sherlock    Holmes       Mr.  NNP   \n",
      "4               4      Mr.  Sherlock    Holmes       Mr.  Sherlock  NNP   \n",
      "...           ...      ...       ...       ...       ...       ...  ...   \n",
      "65446       65446      the    russet    slopes        of       the  NNS   \n",
      "65447       65447   russet    slopes        of       the      moor   IN   \n",
      "65448       65448   slopes        of       the      moor         .   DT   \n",
      "65449       65449       of       the      moor         .         X   NN   \n",
      "65450       65450      the      moor         .         X         X    .   \n",
      "\n",
      "          chunk     lemma  matchesNeg  hasPrefix  hasSuffix  hasPrefixAntonym  \\\n",
      "0            NP   Chapter       False      False      False             False   \n",
      "1      no label        1.       False      False      False             False   \n",
      "2            NP       Mr.       False      False      False             False   \n",
      "3            NP  Sherlock       False      False      False             False   \n",
      "4            NP    Holmes       False      False      False             False   \n",
      "...         ...       ...         ...        ...        ...               ...   \n",
      "65446        VP     slope       False      False      False             False   \n",
      "65447        VP        of       False      False      False             False   \n",
      "65448        VP       the       False      False      False             False   \n",
      "65449        VP      moor       False      False      False             False   \n",
      "65450  no label         .       False      False      False             False   \n",
      "\n",
      "       hasSuffixAntonym  matchesMulticue bio  \n",
      "0                 False            False   O  \n",
      "1                 False            False   O  \n",
      "2                 False            False   O  \n",
      "3                 False            False   O  \n",
      "4                 False            False   O  \n",
      "...                 ...              ...  ..  \n",
      "65446             False            False   O  \n",
      "65447             False            False   O  \n",
      "65448             False            False   O  \n",
      "65449             False            False   O  \n",
      "65450             False            False   O  \n",
      "\n",
      "[65451 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.fillna('X')\n",
    "dev_df = dev_df.fillna('X')\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances = train_df[[\"token\", \"token-2\", \"token-1\", \"token+1\", \"token+2\", \"pos\", \"chunk\", \"lemma\", \"matchesNeg\", \"hasPrefix\", \"hasSuffix\", \"hasPrefixAntonym\", \"hasSuffixAntonym\", \"matchesMulticue\"]].to_dict('records')\n",
    "dev_instances = dev_df[[\"token\", \"token-2\", \"token-1\", \"token+1\", \"token+2\", \"pos\", \"chunk\", \"lemma\", \"matchesNeg\", \"hasPrefix\", \"hasSuffix\", \"hasPrefixAntonym\", \"hasSuffixAntonym\", \"matchesMulticue\"]].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vec.fit_transform(train_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_df.bio.tolist()\n",
    "Y_dev = dev_df.bio.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LinearSVC(max_iter = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(C=(0.01, 0.1, 1.0), loss=('hinge', 'squared_hinge'), tol=(0.0001,0.001,0.01,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The GridSearchCV was inspired by the sklearn documentation and lecture by Ilia Markov \n",
    "grid = GridSearchCV(estimator=classifier, param_grid=parameters, cv=5, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(max_iter=10000),\n",
       "             param_grid={'C': (0.01, 0.1, 1.0),\n",
       "                         'loss': ('hinge', 'squared_hinge'),\n",
       "                         'tol': (0.0001, 0.001, 0.01, 0.1)},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'C': 1.0, 'loss': 'hinge', 'tol': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "classifier = grid.best_estimator_\n",
    "print(\"Best parameters\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = vec.transform(dev_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df['SVM'] = predictions\n",
    "\n",
    "correct_values = dev_df['token'][(dev_df[\"bio\"]=='B-NEG') & (dev_df['SVM'] == 'B-NEG')]\n",
    "correct_values.to_csv('correct_values.csv')\n",
    "non_correct_values = dev_df[['token', 'bio', 'SVM']][dev_df[\"bio\"] != dev_df['SVM']]\n",
    "non_correct_values.to_csv('non_correct_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [\"token\", \"token-2\", \"token-1\", \"token+1\", \"token+2\", \"pos\", \"chunk\", \"lemma\", \"matchesNeg\", \"hasPrefix\", \"hasSuffix\", \"hasPrefixAntonym\", \"hasSuffixAntonym\", \"matchesMutlicue\"]\n",
    "report = pd.DataFrame(classification_report(y_true=dev_df['bio'], y_pred=dev_df['SVM'], output_dict=True)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score       support\n",
      "B-NEG          0.945455  0.886364  0.914956    176.000000\n",
      "I-NEG          1.000000  0.666667  0.800000      3.000000\n",
      "O              0.998433  0.999328  0.998880  13388.000000\n",
      "accuracy       0.997789  0.997789  0.997789      0.997789\n",
      "macro avg      0.981296  0.850786  0.904612  13567.000000\n",
      "weighted avg   0.997746  0.997789  0.997747  13567.000000\n",
      "\n",
      "Features: ['token', 'token-2', 'token-1', 'token+1', 'token+2', 'pos', 'chunk', 'lemma', 'matchesNeg', 'hasPrefix', 'hasSuffix', 'hasPrefixAntonym', 'hasSuffixAntonym', 'matchesMutlicue']\n"
     ]
    }
   ],
   "source": [
    "print(report)\n",
    "print()\n",
    "print(\"Features:\", target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
